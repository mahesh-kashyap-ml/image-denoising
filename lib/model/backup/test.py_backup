# --------------------------------------------------------
# Tensorflow Faster R-CNN
# Licensed under The MIT License [see LICENSE for details]
# Written by Xinlei Chen
# --------------------------------------------------------
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import cv2
import numpy as np
try:
  import cPickle as pickle
except ImportError:
  import pickle
import os
import math
from skimage.util import random_noise
from skimage.restoration import (denoise_wavelet, estimate_sigma)
from sklearn.cluster import MiniBatchKMeans
from scipy.stats import uniform
from scipy.stats import gamma
from scipy.stats import rayleigh
import datetime
import tensorflow as tf
import random
from skimage import img_as_float

import matplotlib.pyplot as plt
from utils.timer import Timer
from utils.blob import im_list_to_blob

from model.config import cfg, get_output_dir
from model.bbox_transform import clip_boxes, bbox_transform_inv
from model.nms_wrapper import nms

def _get_image_blob(im):
  """Converts an image into a network input.
  Arguments:
    im (ndarray): a color image in BGR order
  Returns:
    blob (ndarray): a data blob holding an image pyramid
    im_scale_factors (list): list of image scales (relative to im) used
      in the image pyramid
  """
  im_orig = im.astype(np.float32, copy=True)
  im_orig -= cfg.PIXEL_MEANS
  #PIXEL_MEANS = np.array([[[0.36462913, 0.39009895, 0.41216644]]])
  #im_orig -= PIXEL_MEANS

  im_shape = im_orig.shape
  im_size_min = np.min(im_shape[0:2])
  im_size_max = np.max(im_shape[0:2])

  processed_ims = []
  im_scale_factors = []

  for target_size in cfg.TEST.SCALES:
    im_scale = float(target_size) / float(im_size_min)
    # Prevent the biggest axis from being more than MAX_SIZE
    if np.round(im_scale * im_size_max) > cfg.TEST.MAX_SIZE:
      im_scale = float(cfg.TEST.MAX_SIZE) / float(im_size_max)
    im = cv2.resize(im_orig, None, None, fx=im_scale, fy=im_scale,
            interpolation=cv2.INTER_LINEAR)
    im_scale_factors.append(im_scale)
    processed_ims.append(im)

  # Create a blob to hold the input images
  blob = im_list_to_blob(processed_ims)

  return blob, np.array(im_scale_factors)

def _get_blobs(im):
  """Convert an image and RoIs within that image into network inputs."""
  blobs = {}
  blobs['data'], im_scale_factors = _get_image_blob(im)

  return blobs, im_scale_factors

def _clip_boxes(boxes, im_shape):
  """Clip boxes to image boundaries."""
  # x1 >= 0
  boxes[:, 0::4] = np.maximum(boxes[:, 0::4], 0)
  # y1 >= 0
  boxes[:, 1::4] = np.maximum(boxes[:, 1::4], 0)
  # x2 < im_shape[1]
  boxes[:, 2::4] = np.minimum(boxes[:, 2::4], im_shape[1] - 1)
  # y2 < im_shape[0]
  boxes[:, 3::4] = np.minimum(boxes[:, 3::4], im_shape[0] - 1)
  return boxes

def _rescale_boxes(boxes, inds, scales):
  """Rescale boxes according to image rescaling."""
  for i in range(boxes.shape[0]):
    boxes[i,:] = boxes[i,:] / scales[int(inds[i])]

  return boxes

def im_detect(sess, net, im):
  blobs, im_scales = _get_blobs(im)
  assert len(im_scales) == 1, "Only single-image batch implemented"

  im_blob = blobs['data']
  blobs['im_info'] = np.array([im_blob.shape[1], im_blob.shape[2], im_scales[0]], dtype=np.float32)

  _, scores, bbox_pred, rois = net.test_image(sess, blobs['data'], blobs['im_info'])
  
  boxes = rois[:, 1:5] / im_scales[0]
  scores = np.reshape(scores, [scores.shape[0], -1])
  bbox_pred = np.reshape(bbox_pred, [bbox_pred.shape[0], -1])
  if cfg.TEST.BBOX_REG:
    # Apply bounding-box regression deltas
    box_deltas = bbox_pred
    pred_boxes = bbox_transform_inv(boxes, box_deltas)
    pred_boxes = _clip_boxes(pred_boxes, im.shape)
  else:
    # Simply repeat the boxes, once for each class
    pred_boxes = np.tile(boxes, (1, scores.shape[1]))

  return scores, pred_boxes

def apply_nms(all_boxes, thresh):
  """Apply non-maximum suppression to all predicted boxes output by the
  test_net method.
  """
  num_classes = len(all_boxes)
  num_images = len(all_boxes[0])
  nms_boxes = [[[] for _ in range(num_images)] for _ in range(num_classes)]
  for cls_ind in range(num_classes):
    for im_ind in range(num_images):
      dets = all_boxes[cls_ind][im_ind]
      if dets == []:
        continue

      x1 = dets[:, 0]
      y1 = dets[:, 1]
      x2 = dets[:, 2]
      y2 = dets[:, 3]
      scores = dets[:, 4]
      inds = np.where((x2 > x1) & (y2 > y1))[0]
      dets = dets[inds,:]
      if dets == []:
        continue

      keep = nms(dets, thresh)
      if len(keep) == 0:
        continue
      nms_boxes[cls_ind][im_ind] = dets[keep, :].copy()
  return nms_boxes


"""def vis_detections(im, class_name, dets, thresh=0.5):
        Draw detected bounding boxes.
        inds = np.where(dets[:, -1] >= thresh)[0]
        print(inds)
        if len(inds) == 0:
            return
        im = im[:, :, (2, 1, 0)]
        fig, ax = plt.subplots(figsize=(12, 12))
        ax.imshow(im, aspect='equal')
        for ind in inds:
            print("now here")
            bbox = dets[ind, :4]
            score = dets[ind, -1]

            ax.add_patch(
                    plt.Rectangle((bbox[0], bbox[1]),
                        bbox[2] - bbox[0], 
                        bbox[3] - bbox[1], fill=False,
                        edgecolor='red', linewidth=3.5)
                    )
            ax.text(bbox[0], bbox[1] - 2,
                    '{:s} {:.3f}'.format(class_name, score),
                    bbox=dict(facecolor='blue', alpha=0.5),
                    fontsize=14, color='white')
        ax.set_title(('{} detections with '
            'p({} | box) >= {:.1f}').format(class_name, class_name,thresh),
                  fontsize=14)
        plt.axis('off')
        plt.tight_layout()
        print(i)
        plt.savefig(str(i) +'.png')"""

def test_net(sess, net, imdb, weights_filename, noise, max_per_image=100, thresh=0.):
  np.random.seed(cfg.RNG_SEED)
  """Test a Fast R-CNN network on an image database."""
  num_images = len(imdb.image_index)
  # all detections are collected into:
  #  all_boxes[cls][image] = N x 5 array of detections in
  #  (x1, y1, x2, y2, score)
  all_boxes = [[[] for _ in range(num_images)]
         for _ in range(imdb.num_classes)]

  output_dir = get_output_dir(imdb, weights_filename)
  current_time = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
  #test_log_dir = 'logs/gradient_tape/' + current_time + '/test'
  test_log_dir = 'logs/gradient_tape/test/' + noise +'/'
  test_summary_writer = tf.summary.FileWriter(test_log_dir)
  # timers
  _t = {'im_detect' : Timer(), 'misc' : Timer()}

  for i in range(num_images):
  #for i in range(1):
    img = cv2.imread(imdb.image_path_at(i))
    #print("Noise type is:" + noise)
    #img = cv2.imread('/home/mahesh/thesis/de-noise/tf-faster-rcnn/extra_images/test1.jpg')
    #introduce noise for testing
    
    #gauss_array = random_noise(img, mode='gaussian', var=0.04)
    #im = (255 * gauss_array).astype(np.uint8)
    
    #use filter to remove noise
    #im = cv2.GaussianBlur(im_noise, (3,3), 0)

    #sigma_est = estimate_sigma(im_noise, multichannel=True, average_sigmas=True)
    """im = denoise_wavelet(im_noise, method='VisuShrink', mode='soft',
                                 sigma = sigma_est/2, wavelet_levels=3,
                                 multichannel= True, wavelet = 'coif5')"""
    #cv2.imwrite(str(i) +'.png', im)

    """im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                 wavelet_levels=3,
                                 multichannel= True, convert2ycbcr=True, wavelet = 'coif5')"""
    #data = (255 * im_bayes)
    #im = data.astype(np.uint8)
    """if ('gaussian' in noise):
        im = cv2.imread(imdb.image_path_at(i))
        print('gaussian original')
    elif ('poisson' in noise):
        im = cv2.imread(imdb.image_path_at(i))
        print('poisson original')
    elif ('sap' in noise):
        im = cv2.imread(imdb.image_path_at(i))
        print("s&p original")
    elif ('speckle' in noise):
        im = cv2.imread(imdb.image_path_at(i))
        print("Speckle original")
    elif ('quant' in noise):
        im = cv2.imread(imdb.image_path_at(i))
        print("Quantization original")
    elif('uniform' in noise):
        im = cv2.imread(imdb.image_path_at(i))
        print("uniform original")
    elif ('brownian' in noise):
        im = cv2.imread(imdb.image_path_at(i))
        print("Brownian original")
    elif ('periodic' in noise):
        im = cv2.imread(imdb.image_path_at(i))
        print("Periodic original")
    elif ('gamma' in noise):
        im = cv2.imread(imdb.image_path_at(i))
        print("Gamma original")
    elif ('rayleigh' in noise):
        im = cv2.imread(imdb.image_path_at(i))
        print("Rayleigh original")"""
    
    if ('gaussian' in noise):
        #img = cv2.imread(roidb[i]['image'])
        #To infer on original images, uncomment the below part.
        if ('gaussian_wavelet' in noise):
            if ('var0.4' in noise):
                im_noise = random_noise(img, mode='gaussian', var=0.4)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('gaussian wavelet var 0.4')
            elif ('var1.0' in noise):
                im_noise = random_noise(img, mode='gaussian', var=1.0)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('gaussian wavelet var 1.0')
            elif ('var1.5' in noise):
                im_noise = random_noise(img, mode='gaussian', var=1.5)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('gaussian wavelet var 1.5')
        elif('gaussian_gausblur' in noise):
            size = 3
            if ('var0.4' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=0.4)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('gaussian blur var 0.4')
            elif ('var1.0' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=1.0)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('gaussian blur var 1.0')
            elif ('var1.5' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=1.5)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('gaussian blur var 1.5')
        elif('gaussian_mean' in noise):
            size = 3
            if ('var0.4' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=0.4)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('gaussian mean var 0.4')
            elif ('var1.0' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=1.0)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('gaussian mean var 1.0')
            elif ('var1.5' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=1.5)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('gaussian mean var 1.5')
        elif('gaussian_median' in noise):
            size = 3
            if ('var0.4' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=0.4)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('gaussian median var 0.4')
            elif ('var1.0' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=1.0)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('gaussian median var 1.0')
            elif ('var1.5' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=1.5)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('gaussian median var 1.5')
        elif('gaussian_bilateral' in noise):
            diameter = 9      #the diameter of each pixel in the neighborhood used during filtering
            sigmaColor = 20     #sigma of grey/color space.
            sigmaSpace = 100    #Large value means farther pixels influence each other.
            if ('var0.4' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=0.4)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('gaussian bilateral var 0.4')
            elif ('var1.0' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=1.0)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('gaussian bilateral var 1.0')
            elif ('var1.5' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=1.5)
                im_noise = (255 * gauss_array).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('gaussian bilateral var 1.5')
        else:
            if ('var0.4' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=0.4)
                im = (255 * gauss_array).astype(np.uint8)
                print('gaussian var 0.4')
            elif ('var1.0' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=1.0)
                im = (255 * gauss_array).astype(np.uint8)
                print('gaussian var 1.0')
            elif ('var1.5' in noise):
                gauss_array = random_noise(img, mode='gaussian', var=1.5)
                im = (255 * gauss_array).astype(np.uint8)
                print('gaussian var 1.5')
        print("Gaussian")
    elif ('poisson' in noise):
        #img = cv2.imread(roidb[i]['image'])
        #introduce poisson noise.
        #also called shot noise originates from the discrete nature of electronic charge or photons.
        if ('poisson_wavelet' in noise):
            pois_array = random_noise(img, mode='poisson')
            im_noise = (255 * pois_array).astype(np.uint8)
            im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
            data = (255 * im_bayes)
            im = data.astype(np.uint8)
            print('poisson wavelet')
        elif('poisson_gausblur' in noise):            
            size = 3
            pois_array = random_noise(img, mode='poisson')
            im_noise = (255 * pois_array).astype(np.uint8)
            im = cv2.GaussianBlur(im_noise, (size, size), 0)
            print('poisson noise with gaussian blur')
        elif('poisson_mean' in noise):
            size = 3
            pois_array = random_noise(img, mode='poisson')
            im_noise = (255 * pois_array).astype(np.uint8)
            im = cv2.blur(im_noise, (size, size))
            print('poisson noise with mean filter')
        elif('poisson_median' in noise):
            size = 3
            pois_array = random_noise(img, mode='poisson')
            im_noise = (255 * pois_array).astype(np.uint8)
            im = cv2.medianBlur(im_noise, size)
            print('poisson noise with median filter')
        elif('poisson_bilateral' in noise):
            diameter = 9      #the diameter of each pixel in the neighborhood used during filtering
            sigmaColor = 20     #sigma of grey/color space.
            sigmaSpace = 100    #Large value means farther pixels influence each other.
            pois_array = random_noise(img, mode='poisson')
            im_noise = (255 * pois_array).astype(np.uint8)
            im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
            print('poisson noise with  bilateral filter')
        else:
            pois_array = random_noise(img, mode='poisson')
            im = (255 * pois_array).astype(np.uint8)
            print('poisson noise')
    elif ('sap' in noise):
        #img = cv2.imread(roidb[i]['image'])
        if ('sap_wavelet' in noise):
            if ('var0.2' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.2)
                im_bayes = denoise_wavelet(sp_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('wavelet')
                print('s&p wavelet var 0.2')
            elif ('var0.4' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.4)
                im_bayes = denoise_wavelet(sp_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('wavelet')
                print('s&p wavelet var 0.4')
            elif ('var0.8' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.8)
                im_bayes = denoise_wavelet(sp_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('wavelet')
                print('s&p wavelet var 0.8')
        elif('sap_gausblur' in noise):
            size = 3
            if ('var0.2' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.2)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('s&p gaus filter var 0.2')
            elif ('var0.4' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.4)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('s&p gaus filter var 0.4')
            elif ('var0.8' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.8)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('s&p gaus filter var 0.8')
        elif('sap_mean' in noise):
            size = 3
            if ('var0.2' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.2)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('s&p mean var 0.2')
            elif ('var0.4' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.4)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('s&p mean var 0.4')
            elif ('var0.8' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.8)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('s&p mean var 0.8')
        elif('sap_median' in noise):
            size = 3
            if ('var0.2' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.2)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('s&p median var 0.2')
            elif ('var0.4' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.4)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('s&p median var 0.4')
            elif ('var0.8' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.8)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('s&p median var 0.8')
        elif('sap_bilateral' in noise):
            diameter = 9      #the diameter of each pixel in the neighborhood used during filtering
            sigmaColor = 20     #sigma of grey/color space.
            sigmaSpace = 100    #Large value means farther pixels influence each other.
            if ('var0.2' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.2)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('s&p bilateral var 0.2')
            elif ('var0.4' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.4)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('s&p bilateral var 0.4')
            elif ('var0.8' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.8)
                im_noise = (255 * sp_array).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('s&p bilateral var 0.8')
        else:
            if ('var0.2' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.2)
                im = (255 * sp_array).astype(np.uint8)
                print('s&p var 0.2')
            elif ('var0.4' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.4)
                im = (255 * sp_array).astype(np.uint8)
                print('s&p var 0.4')
            elif ('var0.8' in noise):
                sp_array = random_noise(img, mode='s&p', amount=0.8)
                im = (255 * sp_array).astype(np.uint8)
                print('s&p var 0.8')
        print("salt & pepper")
    elif ('speckle' in noise):
        #img = cv2.imread(roidb[i]['image'])
        if ('speckle_wavelet' in noise):
            if ('var0.5' in noise):
                speck_array = random_noise(img, mode='speckle', var=0.5)
                im_bayes = denoise_wavelet(speck_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('speckle wavelet var 0.4')
            elif ('var1.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=1.0)
                im_bayes = denoise_wavelet(speck_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('speckle wavelet var 1.0')
            elif ('var2.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=2.0)
                im_bayes = denoise_wavelet(speck_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('speckle wavelet var 2.0')
        elif('speckle_gausblur' in noise):
            size = 3
            if ('var0.5' in noise):
                speck_array = random_noise(img, mode='speckle', var=0.5)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('speckle gaus blur var 0.5')
            elif ('var1.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=1.0)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('speckle gaus blur 1.0')
            elif ('var2.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=2.0)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('speckle gaus blur 2.0')            
        elif('speckle_mean' in noise):
            size = 3
            if ('var0.5' in noise):
                speck_array = random_noise(img, mode='speckle', var=0.5)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('speckle mean var 0.5')
            elif ('var1.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=1.0)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('speckle mean 1.0')
            elif ('var2.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=2.0)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('speckle mean 2.0')
        elif('speckle_median' in noise):
            size = 3
            if ('var0.5' in noise):
                speck_array = random_noise(img, mode='speckle', var=0.5)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('speckle median var 0.5')
            elif ('var1.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=1.0)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('speckle median 1.0')
            elif ('var2.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=2.0)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('speckle median 2.0')
        elif('speckle_bilateral' in noise):
            diameter = 9      #the diameter of each pixel in the neighborhood used during filtering
            sigmaColor = 20     #sigma of grey/color space.
            sigmaSpace = 100    #Large value means farther pixels influence each other.
            if ('var0.5' in noise):
                speck_array = random_noise(img, mode='speckle', var=0.5)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('speckle bilateral var 0.5')
            elif ('var1.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=1.0)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('speckle bilateral 1.0')
            elif ('var2.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=2.0)
                im_noise = (255 * speck_array).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('speckle bilateral 2.0')
        else:
            if ('var0.5' in noise):
                speck_array = random_noise(img, mode='speckle', var=0.5)
                im = (255 * speck_array).astype(np.uint8)
                print('speckle var 0.5')
            elif ('var1.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=1.0)
                im = (255 * speck_array).astype(np.uint8)
                print('speckle var 1.0')
            elif ('var2.0' in noise):
                speck_array = random_noise(img, mode='speckle', var=2.0)
                im = (255 * speck_array).astype(np.uint8)
                print('speckle var 2.0')
        print("Speckle")    
    elif ('quant' in noise):
        #img = cv2.imread(roidb[i]['image'])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        h, w = img.shape[:2]
        #clor quantization, using K-Means clustering. 
        #Usually this noise is found while converting analog to digital, or continuous random variable to discreate.
        image = img.reshape((img.shape[0] * img.shape[1], 3))
        if ('quant_wavelet' in noise):
            if ('var3' in noise):
                clt = MiniBatchKMeans(n_clusters= 3)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                quant_array = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im_bayes = denoise_wavelet(quant_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('quantization wavelet with cluster 3')
            elif ('var7' in noise):
                clt = MiniBatchKMeans(n_clusters= 7)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                quant_array = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im_bayes = denoise_wavelet(quant_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('quantization wavelet with cluster 7')
            elif ('var10' in noise):
                clt = MiniBatchKMeans(n_clusters= 10)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                quant_array = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im_bayes = denoise_wavelet(quant_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('quantization wavelet with cluster 10')
        elif('quant_gausblur' in noise):
            size = 3
            if ('var3' in noise):
                clt = MiniBatchKMeans(n_clusters= 3)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('quantization gausblur with cluster 3')
            elif ('var7' in noise):
                clt = MiniBatchKMeans(n_clusters= 7)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('quantization gasublur with cluster 7')
            elif ('var10' in noise):
                clt = MiniBatchKMeans(n_clusters= 10)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('quantization gausblur with cluster 10')
        elif('quant_mean' in noise):
            size = 3
            if ('var3' in noise):
                clt = MiniBatchKMeans(n_clusters= 3)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.blur(im_noise, (size, size))
                print('quantization mean with cluster 3')
            elif ('var7' in noise):
                clt = MiniBatchKMeans(n_clusters= 7)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.blur(im_noise, (size, size))
                print('quantization mean with cluster 7')
            elif ('var10' in noise):
                clt = MiniBatchKMeans(n_clusters= 10)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.blur(im_noise, (size, size))
                print('quantization mean with cluster 10')
        elif('quant_median' in noise):
            size = 3
            if ('var3' in noise):
                clt = MiniBatchKMeans(n_clusters= 3)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.medianBlur(im_noise, size)
                print('quantization median with cluster 3')
            elif ('var7' in noise):
                clt = MiniBatchKMeans(n_clusters= 7)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.medianBlur(im_noise, size)
                print('quantization median with cluster 7')
            elif ('var10' in noise):
                clt = MiniBatchKMeans(n_clusters= 10)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.medianBlur(im_noise, size)
                print('quantization median with cluster 10')
        elif('quant_bilateral' in noise):
            diameter = 9      #the diameter of each pixel in the neighborhood used during filtering
            sigmaColor = 20     #sigma of grey/color space.
            sigmaSpace = 100    #Large value means farther pixels influence each other.
            if ('var3' in noise):
                clt = MiniBatchKMeans(n_clusters= 3)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('quantization bilateral with cluster 3')
            elif ('var7' in noise):
                clt = MiniBatchKMeans(n_clusters= 7)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('quantization bilateral with cluster 7')
            elif ('var10' in noise):
                clt = MiniBatchKMeans(n_clusters= 10)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im_noise = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('quantization bilateral with cluster 10')
        else:
            if ('var3' in noise):                
                clt = MiniBatchKMeans(n_clusters= 3)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                print('quantization with cluster 3')
            elif ('var7' in noise):
                clt = MiniBatchKMeans(n_clusters= 7)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                print('quantization with cluster 7')
            elif ('var10' in noise):
                clt = MiniBatchKMeans(n_clusters= 10)
                labels = clt.fit_predict(image)
                quant = clt.cluster_centers_.astype("uint8")[labels]
                quant = quant.reshape(h, w, 3)
                im = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
                print('quantization with cluster 10')
        print("Quantization")
    elif('uniform' in noise):
        #img = cv2.imread(roidb[i]['image'])
        image = img_as_float(img)
        if ('uniform_wavelet' in noise):
            if ('var0.2' in noise):
                uniform_array = np.random.uniform(low=0., high=0.2, size=img.shape)
                im_noise = cv2.add(image, uniform_array)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('wavelet')
                print('uniform wavelet var 0.2')
            elif ('var0.6' in noise):
                uniform_array = np.random.uniform(low=0., high=0.6, size=img.shape)
                im_noise = cv2.add(image, uniform_array)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('wavelet')
                print('uniform wavelet var 0.6')
            elif ('var1.2' in noise):
                uniform_array = np.random.uniform(low=0., high=1.2, size=img.shape)
                im_noise = cv2.add(image, uniform_array)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('wavelet')
                print('uniform wavelet var 1.2')
        elif('uniform_gausblur' in noise):
            size = 3
            if ('var0.2' in noise):
                uniform_array = np.random.uniform(low=0., high=0.2, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('uniform var 0.2')
            elif ('var0.6' in noise):
                uniform_array = np.random.uniform(low=0., high=0.6, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('uniform var 0.6')
            elif ('var1.2' in noise):
                uniform_array = np.random.uniform(low=0., high=1.2, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('uniform var 1.2')
        elif('uniform_mean' in noise):
            size = 3
            if ('var0.2' in noise):
                uniform_array = np.random.uniform(low=0., high=0.2, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('uniform mean var 0.2')
            elif ('var0.6' in noise):
                uniform_array = np.random.uniform(low=0., high=0.6, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('uniform mean var 0.6')
            elif ('var1.2' in noise):
                uniform_array = np.random.uniform(low=0., high=1.2, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('uniform mean var 1.2')
        elif('uniform_median' in noise):
            size = 3
            if ('var0.2' in noise):
                uniform_array = np.random.uniform(low=0., high=0.2, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('uniform median var 0.2')
            elif ('var0.6' in noise):
                uniform_array = np.random.uniform(low=0., high=0.6, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('uniform median var 0.6')
            elif ('var1.2' in noise):
                uniform_array = np.random.uniform(low=0., high=1.2, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('uniform median var 1.2')
        elif('uniform_bilateral' in noise):
            diameter = 9      #the diameter of each pixel in the neighborhood used during filtering
            sigmaColor = 20     #sigma of grey/color space.
            sigmaSpace = 100    #Large value means farther pixels influence each other.
            if ('var0.2' in noise):
                uniform_array = np.random.uniform(low=0., high=0.2, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('uniform bilateral var 0.2')
            elif ('var0.6' in noise):
                uniform_array = np.random.uniform(low=0., high=0.6, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('uniform bilateral var 0.6')
            elif ('var1.2' in noise):
                uniform_array = np.random.uniform(low=0., high=1.2, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im_noise = (255 * uniform_noise).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('uniform bilateral var 1.2')
        else:
            if ('var0.2' in noise):            
                uniform_array = np.random.uniform(low=0., high=0.2, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im = (255 * uniform_noise).astype(np.uint8)
                print('uniform var 0.2')
            elif ('var0.6' in noise):
                uniform_array = np.random.uniform(low=0., high=0.6, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im = (255 * uniform_noise).astype(np.uint8)
                print('uniform var 0.6')
            elif ('var1.2' in noise):
                uniform_array = np.random.uniform(low=0., high=1.2, size=img.shape)
                uniform_noise = cv2.add(image, uniform_array)
                im = (255 * uniform_noise).astype(np.uint8)
                print('uniform var 1.2')
        print("uniform")
    elif ('brownian' in noise):
        #img = cv2.imread(roidb[i]['image'])
        h, w = img.shape[:2]
        n=img.size
        #T=n
        #times = np.linspace(0., T, n)
        #dt = times[1] - times[0]
        #Bt2 - Bt1 ~ Normal with mean 0 and variance t2-t1
        #brownian motion's characterstics is its independent normally distributed increments.
        if ('brownian_wavelet' in noise):        
            if ('var0.9' in noise):
                dt = 0.9
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('brownian wavelet var 0.9')
            elif ('var0.09' in noise):
                dt = 0.09
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('brownian wavelet var 0.09')
            elif ('var0.009' in noise):
                dt = 0.009
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('brownian wavelet var 0.009')
        elif('brownian_gausblur' in noise):
            size = 3
            if ('var0.9' in noise):
                dt = 0.9
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                #brownian motion starts at zero
                B0 = np.zeros(shape=(1,))
                #brownian motion is to concatenate the intial value with the cumulative sum of the increments.
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('brownian gausblur 0.9')
            elif ('var0.09' in noise):
                dt = 0.09
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('brownian gausblur 0.09')
            elif ('var0.009' in noise):
                dt = 0.009
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('brownian gausblur 0.009')
        elif('brownian_mean' in noise):
            size = 3
            if ('var0.9' in noise):
                dt = 0.9
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                #brownian motion starts at zero
                B0 = np.zeros(shape=(1,))
                #brownian motion is to concatenate the intial value with the cumulative sum of the increments.
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.blur(im_noise, (size, size))
                print('brownian mean 0.9')
            elif ('var0.09' in noise):
                dt = 0.09
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.blur(im_noise, (size, size))                
                print('brownian mean 0.09')
            elif ('var0.009' in noise):
                dt = 0.009
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.blur(im_noise, (size, size))
                print('brownian mean 0.009')
        elif('brownian_median' in noise):
            size = 3
            if ('var0.9' in noise):
                dt = 0.9
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                #brownian motion starts at zero
                B0 = np.zeros(shape=(1,))
                #brownian motion is to concatenate the intial value with the cumulative sum of the increments.
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.medianBlur(im_noise, size)
                print('brownian median 0.9')
            elif ('var0.09' in noise):
                dt = 0.09
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.medianBlur(im_noise, size)
                print('brownian median 0.09')
            elif ('var0.009' in noise):
                dt = 0.009
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.medianBlur(im_noise, size)
                print('brownian median 0.009')
        elif('brownian_bilateral' in noise):
            diameter = 9      #the diameter of each pixel in the neighborhood used during filtering
            sigmaColor = 20     #sigma of grey/color space.
            sigmaSpace = 100    #Large value means farther pixels influence each other.
            if ('var0.9' in noise):
                dt = 0.9
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                #brownian motion starts at zero
                B0 = np.zeros(shape=(1,))
                #brownian motion is to concatenate the intial value with the cumulative sum of the increments.
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('brownian bilateral 0.9')
            elif ('var0.09' in noise):
                dt = 0.09
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('brownian bilateral 0.09')
            elif ('var0.009' in noise):
                dt = 0.009
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im_noise = cv2.add(img, brownian_noise)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('brownian bilateral 0.009')
        else:
            if ('var0.9' in noise):                
                dt = 0.9
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                #brownian motion starts at zero
                B0 = np.zeros(shape=(1,))
                #brownian motion is to concatenate the intial value with the cumulative sum of the increments.
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im = cv2.add(img, brownian_noise)                
                print('brownian var 0.9')
            elif ('var0.09' in noise):
                dt = 0.09
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im = cv2.add(img, brownian_noise)                
                print('brownian var 0.09')
            elif ('var0.009' in noise):
                dt = 0.009
                dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
                B0 = np.zeros(shape=(1,))
                B = np.concatenate((B0, np.cumsum(dB)))
                brownian = (B * 255).astype(np.uint8)
                brownian_noise = brownian.reshape(h,w,3)
                im = cv2.add(img, brownian_noise)                
                print('brownian var 0.009')
        print("Brownian")
    elif ('periodic' in noise):
        #img = cv2.imread(roidb[i]['image'])
        h, w = img.shape[:2]
        size = img.size
        if ('periodic_wavelet' in noise):
            if ('var3.14' in noise):
                time = (np.linspace(-np.pi, np.pi, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)                
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('periodic wavelet amplitude pi')
            elif ('var100' in noise):
                time = (np.linspace(-100, 100, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)                
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('periodic wavelet amplitude 100')
            elif ('varsize' in noise):
                time = (np.linspace(-size, size, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)                
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('periodic wavelet amplitude size')
        elif('periodic_gausblur' in noise):
            k_size = 3
            if ('var3.14' in noise):
                time = (np.linspace(-np.pi, np.pi, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.GaussianBlur(im_noise, (k_size, k_size), 0)
                print('periodic gausblur amplitude pi')
            elif ('var100' in noise):
                time = (np.linspace(-100, 100, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.GaussianBlur(im_noise, (k_size, k_size), 0)
                print('periodic gausblur amplitude 100')
            elif ('varsize' in noise):
                time = (np.linspace(-size, size, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.GaussianBlur(im_noise, (k_size, k_size), 0)
                print('periodic gausblur amplitude size')
        elif('periodic_mean' in noise):
            k_size = 3
            if ('var3.14' in noise):
                time = (np.linspace(-np.pi, np.pi, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.blur(im_noise, (k_size, k_size))
                print('periodic mean amplitude pi')
            elif ('var100' in noise):
                time = (np.linspace(-100, 100, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.blur(im_noise, (k_size, k_size))
                print('periodic mean amplitude 100')
            elif ('varsize' in noise):
                time = (np.linspace(-size, size, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.blur(im_noise, (k_size, k_size))
                print('periodic mean amplitude size')
        elif('periodic_median' in noise):
            k_size = 3
            if ('var3.14' in noise):
                time = (np.linspace(-np.pi, np.pi, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.medianBlur(im_noise, k_size)
                print('periodic median amplitude pi')
            elif ('var100' in noise):
                time = (np.linspace(-100, 100, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.medianBlur(im_noise, k_size)
                print('periodic median amplitude 100')
            elif ('varsize' in noise):
                time = (np.linspace(-size, size, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.medianBlur(im_noise, k_size)
                print('periodic median amplitude size')
        elif('periodic_bilateral' in noise):
            diameter = 9      #the diameter of each pixel in the neighborhood used during filtering
            sigmaColor = 20     #sigma of grey/color space.
            sigmaSpace = 100    #Large value means farther pixels influence each other.
            if ('var3.14' in noise):
                time = (np.linspace(-np.pi, np.pi, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('periodic bilateral amplitude pi')
            elif ('var100' in noise):
                time = (np.linspace(-100, 100, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('periodic bilateral amplitude 100')
            elif ('varsize' in noise):
                time = (np.linspace(-size, size, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im_noise = cv2.add(img, periodic_noise)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('periodic bilateral amplitude size')
        else:
            if ('var3.14' in noise):
                time = (np.linspace(-np.pi, np.pi, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im = cv2.add(img, periodic_noise)                
                print('periodic amplitude pi')
            elif ('var100' in noise):
                time = (np.linspace(-100, 100, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im = cv2.add(img, periodic_noise)                
                print('periodic amplitude 100')
            elif ('varsize' in noise):
                time = (np.linspace(-size, size, size))
                amplitude = np.sin(time)
                periodic_array = (amplitude * 255).astype(np.uint8)
                periodic_noise = periodic_array.reshape(h,w,3)
                im = cv2.add(img, periodic_noise)                
                print('periodic amplitude size')
        print("Periodic")
    elif ('gamma' in noise):
        #img = cv2.imread(roidb[i]['image'])
        image = img_as_float(img)
        a = 1.99
        if ('gamma_wavelet' in noise):
            if ('var0.1' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.1, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_bayes = denoise_wavelet(gamma_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('gamma wavelet var 0.1')
            elif ('var0.3' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.3, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_bayes = denoise_wavelet(gamma_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('gamma wavelet var 0.3')
            elif ('var0.7' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.7, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_bayes = denoise_wavelet(gamma_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('gamma wavelet var 0.7')
        elif('gamma_gausblur' in noise):
            size = 3
            if ('var0.1' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.1, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('gamma gausblur var 0.1')
            elif ('var0.3' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.3, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('gamma gausblur var 0.3')
            elif ('var0.7' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.7, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('gamma gausblur var 0.7')
        elif('gamma_mean' in noise):
            size = 3
            if ('var0.1' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.1, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('gamma mean var 0.1')
            elif ('var0.3' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.3, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('gamma mean var 0.3')
            elif ('var0.7' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.7, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('gamma mean var 0.7')
        elif('gamma_median' in noise):
            size = 3
            if ('var0.1' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.1, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('gamma median var 0.1')
            elif ('var0.3' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.3, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('gamma median var 0.3')
            elif ('var0.7' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.7, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('gamma median var 0.7')
        elif('gamma_bilateral' in noise):
            diameter = 9      #the diameter of each pixel in the neighborhood used during filtering
            sigmaColor = 20     #sigma of grey/color space.
            sigmaSpace = 100    #Large value means farther pixels influence each other.
            if ('var0.1' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.1, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('gamma bilateral var 0.1')
            elif ('var0.3' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.3, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('gamma bilateral var 0.3')
            elif ('var0.7' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.7, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im_noise = (gamma_array * 255).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('gamma bilateral var 0.7')
        else:
            if ('var0.1' in noise):            
                gamma_dist = gamma.rvs(a, loc=0., scale=0.1, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im = (gamma_array * 255).astype(np.uint8)
                print('gamma var 0.1')
            elif ('var0.3' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.3, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im = (gamma_array * 255).astype(np.uint8)
                print('gamma var 0.3')
            elif ('var0.7' in noise):
                gamma_dist = gamma.rvs(a, loc=0., scale=0.7, size=image.shape)
                gamma_array = cv2.add(image, gamma_dist)
                im = (gamma_array * 255).astype(np.uint8)
                print('gamma var 0.7')
        print("Gamma")
    elif ('rayleigh' in noise):
        #img = cv2.imread(roidb[i]['image'])
        image = img_as_float(img)
        if ('rayleigh_wavelet' in noise):
            if ('var0.1' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.1, size=image.shape)                
                rayleigh_array = cv2.add(image, rayleigh_dist)                
                im_bayes = denoise_wavelet(rayleigh_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('rayleigh wavelet var 0.1')
            elif ('var0.2' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.2, size=image.shape)                
                rayleigh_array = cv2.add(image, rayleigh_dist)                
                im_bayes = denoise_wavelet(rayleigh_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('rayleigh wavelet var 0.2')
            elif ('var0.3' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.3, size=image.shape)                
                rayleigh_array = cv2.add(image, rayleigh_dist)                
                im_bayes = denoise_wavelet(rayleigh_array, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)                
                print('rayleigh wavelet var 0.3')
        elif('rayleigh_gausblur' in noise):
            size = 3
            if ('var0.1' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.1, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('rayleigh gausblur 0.1')
            elif ('var0.2' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.2, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('rayleigh gausblur 0.2')
            elif ('var0.3' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.3, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.GaussianBlur(im_noise, (size, size), 0)
                print('rayleigh gausblur 0.3')
        elif('rayleigh_mean' in noise):
            size = 3
            if ('var0.1' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.1, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('rayleigh mean 0.1')
            elif ('var0.2' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.2, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('rayleigh mean 0.2')
            elif ('var0.3' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.3, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.blur(im_noise, (size, size))
                print('rayleigh mean 0.3')
        elif('rayleigh_median' in noise):
            size = 3
            if ('var0.1' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.1, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('rayleigh median 0.1')
            elif ('var0.2' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.2, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('rayleigh median 0.2')
            elif ('var0.3' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.3, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.medianBlur(im_noise, size)
                print('rayleigh median 0.3')
        elif('rayleigh_bilateral' in noise):
            diameter = 9      #the diameter of each pixel in the neighborhood used during filtering
            sigmaColor = 20     #sigma of grey/color space.
            sigmaSpace = 100    #Large value means farther pixels influence each other.
            if ('var0.1' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.1, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('rayleigh bilateral 0.1')
            elif ('var0.2' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.2, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('rayleigh bilateral 0.2')
            elif ('var0.3' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.3, size=image.shape)
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im_noise = (rayleigh_array * 255).astype(np.uint8)
                im = cv2.bilateralFilter(im_noise, diameter, sigmaColor, sigmaSpace, borderType=cv2.BORDER_CONSTANT)
                print('rayleigh bilateral 0.3')
        else:
            if ('var0.1' in noise):         
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.1, size=image.shape)                
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im = (rayleigh_array * 255).astype(np.uint8)
                print('rayleigh var 0.1')
            elif ('var0.2' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.2, size=image.shape)                
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im = (rayleigh_array * 255).astype(np.uint8)
                print('rayleigh var 0.2')
            elif ('var0.3' in noise):
                rayleigh_dist = rayleigh.rvs(loc=0., scale=0.3, size=image.shape)                
                rayleigh_array = cv2.add(image, rayleigh_dist)
                im = (rayleigh_array * 255).astype(np.uint8)
                print('rayleigh var 0.3')
        print("Rayleigh")
    elif (noise == 'wavelet'):
        img = cv2.imread(roidb[i]['image'])
        #introduce gaussian noise.
        gauss_array = random_noise(img, mode='gaussian', var=0.04)
        im_noise = (255 * gauss_array).astype(np.uint8)
        #denoise with gaussian filter.
        #im = cv2.GaussianBlur(noise_im, (3,3), 0)
        #denoise with wavelet visushrink filter.
        #sigma_est = estimate_sigma(im_noise, multichannel=True, average_sigmas=True)
        im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                    wavelet_levels=3,
                                    multichannel= True, convert2ycbcr=True, wavelet = 'coif5')
        data = (255 * im_bayes)
        im = data.astype(np.uint8)
        print('wavelet')
    else:
        im = cv2.imread(roidb[i]['image'])
        #introduce gaussian noise.
        print('original')
    
    
    """if ('gaussian' in noise):
        #img = cv2.imread(roidb[i]['image'])
        if ('gaussian_wavelet' in noise):
            if ('var0.4' in noise):
                im_noise = cv2.imread(imdb.image_path_at(i))
                #var_list = [0.1, 0.3, 0.5, 0.7, 1.2, 1.5]                
                #var = random.choice(var_list)
                #im = cv2.imread(imdb.image_path_at(i))
                #im_noise = random_noise(img, mode='gaussian', var=var)
                #im = (255 * im_noise).astype(np.uint8)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                wavelet_levels=3,
                                multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('wavelet')
                print('gaussian wavelet var 0.4')
            elif ('var1.0' in noise):
                im_noise = cv2.imread(imdb.image_path_at(i))
                #im_noise = random_noise(img, mode='gaussian', var=1.0)
                #im = (255 * im_noise).astype(np.uint8)
                #im_noise = random_noise(img, mode='gaussian', var=1.0)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                wavelet_levels=3,
                                multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('wavelet')
                print('gaussian wavelet var 1.0')
            elif ('var1.5' in noise):
                #var_list = [0.1, 0.3, 0.5, 0.7, 1.2, 1.5]
                #var = random.choice(var_list)
                im_noise = cv2.imread(imdb.image_path_at(i))
                #print(var)
                #im = cv2.imread(imdb.image_path_at(i))
                #im_noise = random_noise(img, mode='gaussian', var=var)
                #im = (255 * im_noise).astype(np.uint8)
                #im_noise = random_noise(img, mode='gaussian', var=1.0)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                wavelet_levels=3,
                                multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('wavelet')
                print('gaussian wavelet var 1.5')
        else:
            if ('var0.4' in noise):
                im = cv2.imread(imdb.image_path_at(i))
                #var_list = [0.1, 0.3, 0.5, 0.7, 1.2, 1.5]
                #var = random.choice(var_list)
                #im = cv2.imread(imdb.image_path_at(i))
                #print(var)
                gauss_array = random_noise(img, mode='gaussian', var=0.4)
                im = (255 * gauss_array).astype(np.uint8)
                #im_noise = random_noise(img, mode='gaussian', var=var)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',                                
                                multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8i)
                print('gaussian var 0.4')
            elif ('var1.0' in noise):
                im = cv2.imread(imdb.image_path_at(i))
                gauss_array = random_noise(img, mode='gaussian', var=1.0)
                im = (255 * gauss_array).astype(np.uint8)
                im_noise = random_noise(img, mode='gaussian', var=1.0)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                wavelet_levels=3,
                                multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('gaussian var 1.0')
            elif ('var1.5' in noise):
                #var_list = [0.1, 0.3, 0.5, 0.7, 1.2, 1.5]
                #var = random.choice(var_list)
                #print(var)
                im = cv2.imread(imdb.image_path_at(i))
                gauss_array = random_noise(img, mode='gaussian', var=1.0)
                im = (255 * gauss_array).astype(np.uint8)
                im_noise = random_noise(img, mode='gaussian', var=var)
                im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                wavelet_levels=3,
                                multichannel= True, convert2ycbcr=True)
                data = (255 * im_bayes)
                im = data.astype(np.uint8)
                print('gaussian var 1.5')
        print("Gaussian")
    elif (noise == 'poisson'):
        #introduce poisson noise.
        #also called shot noise originates from the discrete nature of electronic charge or photons.
        pois_array = random_noise(img, mode='poisson')
        im = (255 * pois_array).astype(np.uint8)
    elif (noise == 'sp10'):
        #introduce salt and pepper noise.
        #is an impulse noise due to data transmission, failure in memory etc, which causes sharp and sudden disturbance in image signal.
        sp_array = random_noise(img, mode='s&p', amount=0.1)
        im = (255 * sp_array).astype(np.uint8)
    elif (noise == 'speckle'):
        #introduce speckle noise.
        #degrades the quality of image, caused due to random interference between coherent returns issued from many scatteres(particles).
        #adds bright and dark sports in image.
        speck_array = random_noise(img, mode='speckle', var=0.9)
        im = (255 * speck_array).astype(np.uint8)
    elif(noise == 'quant'):
        h, w = img.shape[:2]
        img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        #plt.imshow(image)
        #clor quantization, using K-Means clustering.
        #Usually this noise is found while converting analog to digital, or continuous random variable to discreate.
        image = img.reshape((img.shape[0] * img.shape[1], 3))
        clt = MiniBatchKMeans(n_clusters= 8)
        labels = clt.fit_predict(image)
        quant = clt.cluster_centers_.astype("uint8")[labels]
        quant = quant.reshape(h, w, 3)
        im = cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)
    elif(noise == 'uniform'):
        h, w = img.shape[:2]
        uniform_dist = uniform.rvs(loc=0., scale=1.0, size=img.size)
        uniform_array = (uniform_dist * 255).astype(np.uint8)
        uniform_noise = uniform_array.reshape(h, w, 3)
        im_noise = cv2.add(img, uniform_noise)
    elif(noise == 'brownian'):
        h, w = img.shape[:2]
        n=img.size
        T=n
        times = np.linspace(0., T, n)
        dt = times[1] - times[0]
        #Bt2 - Bt1 ~ Normal with mean 0 and variance t2-t1
        #brownian motion's characterstics is its independent normally distributed increments.
        dB = np.sqrt(dt) * np.random.normal(size=(n-1,))
        #brownian motion starts at zero
        B0 = np.zeros(shape=(1,))
        #brownian motion is to concatenate the intial value with the cumulative sum of the increments.
        B = np.concatenate((B0, np.cumsum(dB)))
        brownian = (B * 255).astype(np.uint8)
        brownian_noise = brownian.reshape(h,w,3)
        im = cv2.add(img, brownian_noise)
    elif(noise == 'periodic'):
        h, w = img.shape[:2]
        size = img.size
        time = (np.linspace(0, size, size))
        amplitude = np.sin(time)
        periodic_array = (amplitude * 255).astype(np.uint8)
        periodic_noise = periodic_array.reshape(h,w,3)
        im = cv2.add(img, periodic_noise)
    elif(noise == 'gamma'):
        h, w = img.shape[:2]
        a = 1.99 #shape parameter, fixed for standard gamma distribution.
        im = cv2.imread(imdb.image_path_at(i))
        size = img.size
        x = np.linspace(gamma.ppf(0.01, a), gamma.ppf(0.99, a), size)
        gamma_dist = gamma.pdf(x,a)
        gamma_array = (gamma_dist * 255).astype(np.uint8)
        gamma_noise = gamma_array.reshape(h, w, 3)
        im = cv2.add(img, gamma_noise)
        gamma_dist = gamma.rvs(a, loc=0., scale=1., size=img.size)
        gamma_array = (gamma_dist * 255).astype(np.uint8)
        gamma_noise = gamma_array.reshape(h, w, 3)
        im = cv2.add(img, gamma_noise)
    elif(noise == 'rayleigh'):
        h, w = img.shape[:2]
        size = img.size
        x = np.linspace(rayleigh.ppf(0.01),rayleigh.ppf(0.99), size)
        rayleigh_dist = rayleigh.pdf(x)
        rayleigh_array = (rayleigh_dist * 255).astype(np.uint8)
        rayleigh_noise = rayleigh_array.reshape(h, w, 3)
        im = cv2.add(img, rayleigh_noise)
        rayleigh_dist = rayleigh.rvs(loc=0., scale=0.4, size=img.size)
        rayleigh_array = (rayleigh_dist * 255).astype(np.uint8)
        rayleigh_noise = rayleigh_array.reshape(h, w, 3)
        im = cv2.add(img, rayleigh_noise)
    elif (noise == 'wavelet'):
        #introduce gaussian noise.
        gauss_array = random_noise(img, mode='gaussian', var=0.04)
        im_noise = (255 * gauss_array).astype(np.uint8)
        #denoise with gaussian filter.
        #im = cv2.GaussianBlur(noise_im, (3,3), 0)
        #denoise with wavelet visushrink filter.
        #sigma_est = estimate_sigma(im_noise, multichannel=True, average_sigmas=True)
        im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                wavelet_levels=3,
                                multichannel= True, convert2ycbcr=True, wavelet = 'coif5')
        data = (255 * im_bayes)
        im_noise = data.astype(np.uint8)
        print('wavelet')
    else:
        #introduce gaussian noise.
        im = cv2.imread(imdb.image_path_at(i))
        print('original')

    #im = cv2.GaussianBlur(im_noise, (3,3), 0)"""

    """im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                wavelet_levels=3,
                                multichannel= True, convert2ycbcr=True, wavelet = 'coif5')"""
    """im_bayes = denoise_wavelet(im_noise, method='BayesShrink', mode='soft',
                                wavelet='coif5',
                                multichannel= True, convert2ycbcr=True)
    data = (255 * im_bayes)
    im = data.astype(np.uint8)
    print('wavelet')"""


    _t['im_detect'].tic()
    scores, boxes = im_detect(sess, net, im)
    _t['im_detect'].toc()
    """with test_summary_writer.as_default():
        tf.summary.scalar('scores', scores)
        #tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)"""
    #testWriter = tf.FileWriter()
    #test_summary_writer.add_summary(scores, float(i))
    #print(scores)
    #print((scores.shape))
    #test_val = net.get_summary(sess, im)
    #test_summary_writer.add_summary(test_val, float(i))


    _t['misc'].tic()

    # skip j = 0, because it's the background class
    #for j, cls in range(enumerate(imdb.classes[1:])):
    for j in range(1, imdb.num_classes):
      inds = np.where(scores[:, j] > thresh)[0]
      cls_scores = scores[inds, j]
      cls_boxes = boxes[inds, j*4:(j+1)*4]
      cls_dets = np.hstack((cls_boxes, cls_scores[:, np.newaxis])) \
        .astype(np.float32, copy=False)
      keep = nms(cls_dets, cfg.TEST.NMS)
      cls_dets = cls_dets[keep, :]
      all_boxes[j][i] = cls_dets
      #vis_detections(im, cls, cls_dets, thresh=0.8)
      inds = np.where(cls_dets[:, -1] >= 0.8)[0]
      for ind in inds:
          score = cls_dets[ind, -1]
          summary = tf.Summary(value=[
              tf.Summary.Value(tag="score", simple_value=score),
              ])
          test_summary_writer.add_summary(summary, float(i))


    # Limit to max_per_image detections *over all classes*
    if max_per_image > 0:
      image_scores = np.hstack([all_boxes[j][i][:, -1]
                    for j in range(1, imdb.num_classes)])
      if len(image_scores) > max_per_image:
        image_thresh = np.sort(image_scores)[-max_per_image]
        for j in range(1, imdb.num_classes):
          keep = np.where(all_boxes[j][i][:, -1] >= image_thresh)[0]
          all_boxes[j][i] = all_boxes[j][i][keep, :]

    _t['misc'].toc()

    #test_summary_writer.add_summary(scores, float(i))

    print('im_detect: {:d}/{:d} {:.3f}s {:.3f}s' \
        .format(i + 1, num_images, _t['im_detect'].average_time,
            _t['misc'].average_time))


    def vis_detections(im, class_name, dets, thresh=0.5):
        #Draw detected bounding boxes.
        #print(dets)
        #print(dets.shape)
        #print(dets[:, -1])
        inds = np.where(dets[:, -1] >= 0.8)[0]
        #print(thresh)
        #print(inds)
        if len(inds) == 0:
            return
        im = im[:, :, (2, 1, 0)]
        fig, ax = plt.subplots(figsize=(12, 12))
        ax.imshow(im, aspect='equal')
        for ind in inds:
            #print("now here")
            bbox = dets[ind, :4]
            score = dets[ind, -1]

            ax.add_patch(
                    plt.Rectangle((bbox[0], bbox[1]),
                        bbox[2] - bbox[0],
                        bbox[3] - bbox[1], fill=False,
                        edgecolor='red', linewidth=3.5)
                    )
            ax.text(bbox[0], bbox[1] - 2,
                    '{:s} {:.3f}'.format(class_name, score),
                    bbox=dict(facecolor='blue', alpha=0.5),
                    fontsize=14, color='white')
        ax.set_title(('{} detections with '
            'p({} | box) >= {:.1f}').format(class_name, class_name,thresh),
                  fontsize=14)
        plt.axis('off')
        plt.tight_layout()
        print(i)
        plt.savefig(str(i) +'.png')

    # Visualize detections for each class
    """CONF_THRESH = 0.8
    NMS_THRESH = 0.3
    for cls_ind, cls in enumerate(imdb.classes[1:]):
        cls_ind += 1 # because we skipped background
        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]
        cls_scores = scores[:, cls_ind]
        dets = np.hstack((cls_boxes,
                          cls_scores[:, np.newaxis])).astype(np.float32)
        keep = nms(dets, NMS_THRESH)
        dets = dets[keep, :]
        vis_detections(im, cls, dets, thresh=CONF_THRESH)"""
    
    """det_file = os.path.join(output_dir, 'detections.pkl')
    with open(det_file, 'wb') as f:
        pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)
    
    print('Evaluating detections')
    imdb.evaluate_detections(all_boxes, output_dir)"""
